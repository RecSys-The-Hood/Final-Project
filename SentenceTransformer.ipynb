{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\recsys\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\recsys\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_descriptions = [\n",
    "    \"This is a spacious house with a beautiful garden.\",\n",
    "    \"Cozy apartment in the heart of downtown.\",\n",
    "    \"Large family home with modern amenities.\",\n",
    "    \"Charming cottage with a scenic view.\",\n",
    "    \"I am a barbie girl in a barbie world.\"\n",
    "]\n",
    "\n",
    "# Tokenize and encode descriptions\n",
    "encoded_descriptions = [tokenizer.encode(description, add_special_tokens=True, max_length=512, truncation=True) for description in house_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(desc) for desc in encoded_descriptions)\n",
    "padded_descriptions = [desc + [0] * (max_len - len(desc)) for desc in encoded_descriptions]\n",
    "\n",
    "# Convert to PyTorch tensors and move to GPU\n",
    "input_ids = torch.tensor(padded_descriptions).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # Use the [CLS] token embeddin\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      "[[1.         0.79469895 0.830658   0.8217503  0.7700808 ]\n",
      " [0.79469895 1.0000001  0.88345337 0.92763567 0.86704135]\n",
      " [0.830658   0.88345337 1.         0.923169   0.8204694 ]\n",
      " [0.8217503  0.92763567 0.923169   1.         0.831722  ]\n",
      " [0.7700808  0.86704135 0.8204694  0.831722   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity Matrix:\")\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Similarity Score: 0.87765425\n"
     ]
    }
   ],
   "source": [
    "average_similarity = np.mean(similarity_matrix)\n",
    "print(\"Average Similarity Score:\", average_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\recsys\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained SentenceTransformer model onto GPU\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# Single list of sentences\n",
    "sentences = [\n",
    "    \"This is a spacious house with a beautiful garden.\",\n",
    "    \"Cozy apartment in the heart of downtown.\",\n",
    "    \"Large family home with modern amenities.\",\n",
    "    \"Charming cottage with a scenic view.\",\n",
    "    \"I am a barbie girl in a barbie world.\",\n",
    "]\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "# Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(cosine_scores.shape[0]):\n",
    "    for j in range(cosine_scores.shape[1]):\n",
    "        if cosine_scores[i][j] != 1.000:\n",
    "            pairs.append({\"index\": [i, j], \"score\": cosine_scores[i][j]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a barbie girl in a barbie world. \t\t I am a barbie girl in a barbie world. \t\t Score: 1.0000\n",
      "Charming cottage with a scenic view. \t\t Charming cottage with a scenic view. \t\t Score: 1.0000\n",
      "This is a spacious house with a beautiful garden. \t\t Large family home with modern amenities. \t\t Score: 0.5722\n",
      "Large family home with modern amenities. \t\t This is a spacious house with a beautiful garden. \t\t Score: 0.5722\n",
      "This is a spacious house with a beautiful garden. \t\t Charming cottage with a scenic view. \t\t Score: 0.5342\n",
      "Charming cottage with a scenic view. \t\t This is a spacious house with a beautiful garden. \t\t Score: 0.5342\n",
      "Cozy apartment in the heart of downtown. \t\t Large family home with modern amenities. \t\t Score: 0.4416\n",
      "Large family home with modern amenities. \t\t Cozy apartment in the heart of downtown. \t\t Score: 0.4416\n",
      "Cozy apartment in the heart of downtown. \t\t Charming cottage with a scenic view. \t\t Score: 0.4315\n",
      "Charming cottage with a scenic view. \t\t Cozy apartment in the heart of downtown. \t\t Score: 0.4315\n"
     ]
    }
   ],
   "source": [
    "pairs = sorted(pairs, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair[\"index\"]\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        sentences[i], sentences[j], pair[\"score\"]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
